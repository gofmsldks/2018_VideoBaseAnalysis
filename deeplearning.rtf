{\rtf1\ansi\ansicpg949\cocoartf2511
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset129 AppleMyungjo;}
{\colortbl;\red255\green255\blue255;\red191\green100\blue38;\red32\green32\blue32;\red153\green168\blue186;
\red86\green132\blue173;\red160\green0\blue163;\red128\green63\blue122;\red117\green114\blue185;\red152\green54\blue29;
\red88\green118\blue71;\red109\green109\blue109;\red254\green187\blue91;}
{\*\expandedcolortbl;;\cssrgb\c80000\c47059\c19608;\cssrgb\c16863\c16863\c16863;\cssrgb\c66275\c71765\c77647;
\cssrgb\c40784\c59216\c73333;\cssrgb\c69804\c0\c69804;\cssrgb\c58039\c33333\c55294;\cssrgb\c53333\c53333\c77647;\cssrgb\c66667\c28627\c14902;
\cssrgb\c41569\c52941\c34902;\cssrgb\c50196\c50196\c50196;\cssrgb\c100000\c77647\c42745;}
\paperw11900\paperh16840\margl1440\margr1440\vieww15060\viewh16100\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs24 \cf2 \cb3 \expnd0\expndtw0\kerning0
mport \cf4 torch\cb1 \
\cf2 \cb3 import \cf4 torch.nn \cf2 as \cf4 nn\cb1 \
\cf2 \cb3 import \cf4 os\cb1 \
\cf2 \cb3 import \cf4 numpy \cf2 as \cf4 np\cb1 \
\cf2 \cb3 from \cf4 torch.utils.data \cf2 import \cf4 DataLoader\cb1 \
\cf2 \cb3 import \cf4 torchvision.datasets \cf2 as \cf4 dsets\cb1 \
\cf2 \cb3 import \cf4 torchvision.transforms \cf2 as \cf4 transforms\cb1 \
\
\cf2 \cb3 from \cf4 torch.autograd \cf2 import \cf4 variable\cb1 \
\cf2 \cb3 import \cf4 cv2\cb1 \
\
\cb3 input_size =\cf5 784\cb1 \
\cf4 \cb3 hidden_size = \cf5 50\cb1 \
\cf4 \cb3 num_classes = \cf5 10\cb1 \
\cf4 \cb3 num_epochs = \cf5 1\cb1 \
\cf4 \cb3 batch_size = \cf5 1\cb1 \
\cf4 \cb3 learning_rate = \cf5 0.001\cb1 \
\
\cf4 \cb3 model = MyNet(input_size\cf2 , \cf4 hidden-size\cf2 ,\cf4 num_classes)\cb1 \
\cb3 loss_func = MyLoss()\cb1 \
\cf2 \cb3 class \cf4 Dataset:\cb1 \
\cb3     \cf2 def \cf6 __init__\cf4 (\cf7 self\cf2 , \cf4 folder_path):\cb1 \
\cb3         \cf7 self\cf4 .n_classes = num_classes\cb1 \
\cb3         \cf7 self\cf4 .all_train_img_list = []\cb1 \
\cb3         \cf7 self\cf4 .all_train_label_list = []\cb1 \
\
\cb3         \cf2 for \cf4 i \cf2 in \cf8 range\cf4 (\cf7 self\cf4 .n_classes):\cb1 \
\cb3             \cf7 self\cf4 .train_list = os.listdir(\cf9 folder_path\cf4 =\cf8 str\cf4 (i))\cb1 \
\cb3             \cf7 self\cf4 .train_list = [folder_path+\cf8 str\cf4 (i)+\cf10 '/'\cf4 +file_name \cf2 for \cf4 file_name \cf2 in \cf7 self\cf4 .train_list]\cb1 \
\cb3             \cf7 self\cf4 .all_train_img_list = \cf7 self\cf4 .all_train_img_list+\cf7 self\cf4 .train_list\cb1 \
\cb3             \cf7 self\cf4 .all_train_img_list = \cf7 self\cf4 .all_train_label_list+[i]*\cf8 len\cf4 (\cf7 self\cf4 .train_list)\cb1 \
\
\cb3     \cf2 def \cf6 __getitem__\cf4 (\cf7 self\cf2 , \cf4 idx):\cb1 \
\cb3         img = cv2.inread(\cf7 self\cf4 .all_train_label_list[idx]\cf2 , \cf4 cv2.IMREAD_GRAYSCALE)\cb1 \
\cb3         img = np.expand_dims(img\cf2 , \cf5 0\cf4 )\cb1 \
\cb3         img = (img/\cf5 255.\cf4 ).astype(np.float32)\cb1 \
\cb3         label = \cf7 self\cf4 .all_train_label_list[idx]\cb1 \
\cb3         label = np.eye(\cf7 self\cf4 .n_classes)[label].astype(np.float32)\cb1 \
\cb3         \cf2 return \cf4 img\cf2 , \cf4 label\cb1 \
\
\cb3     \cf2 def \cf6 __len__\cf4 (\cf7 self\cf4 ):\cb1 \
\cb3         \cf2 return  \cf8 len\cf4 (\cf7 self\cf4 .all_train_img_list)\cb1 \
\
\cf2 \cb3 class \cf4 MyNet(torch.nn.Module):\cb1 \
\cb3     \cf2 def \cf6 __init__\cf4 (\cf7 self\cf2 ,\cf4 input_size\cf2 , \cf4 hidden_size\cf2 , \cf11 num_classes\cf4 ):\cb1 \
\cb3         \cf8 super\cf4 (MyNet\cf2 , \cf7 self\cf4 ).__intit__()\cb1 \
\cb3         \cf7 self\cf4 .fc1 = nn.Linear(input_size\cf2 , \cf4 hidden_size)\cb1 \
\cb3         \cf7 self\cf4 .relu = nn.ReLu()\cb1 \
\cb3         \cf7 self\cf4 .fc2 = nn.Linear(hidden_size\cf2 , \cf4 num-classes)\cb1 \
\
\cb3     \cf2 def \cf12 forward\cf4 (\cf7 self\cf2 , \cf4 x):\cb1 \
\cb3         out = \cf7 self\cf4 .fc1(x)\cb1 \
\cb3         out = \cf7 self\cf4 .relu(out)\cb1 \
\cb3         out = \cf7 self\cf4 .fc2(out)\cb1 \
\cb3         \cf2 return \cf4 out\cb1 \
\
\cf2 \cb3 class \cf4 MyLoss(torch.nn.Module):\cb1 \
\cb3     \cf2 def \cf6 __init__\cf4 (\cf7 self\cf4 ):\cb1 \
\cb3         \cf8 super\cf4 (MyLoss\cf2 , \cf7 self\cf4 ).\cf6 __init__\cf4 ()\cb1 \
\
\cb3     \cf2 def \cf12 forward\cf4 (\cf7 self\cf2 , \cf4 y\cf2 , \cf4 y_pred):\cb1 \
\cb3         \cf2 return \cf4 ((y-y_pred)**\cf5 2\cf4 ).mean()\cb1 \
\
\cf2 \cb3 if \cf4 __name__ = \cf10 '__main__'\cf4 :\cb1 \
\cb3     train_dataset = Dataset(\cf9 folder_path\cf4 =\cf10 ''\cf4 )\cb1 \
\cb3     train_data_loader = DataLoader(train_dataset\cf2 , \cf9 atch_size \cf4 = batch_size\cf2 , \cf9 shuffle \cf4 = \cf2 False, \cf9 num_workers\cf4 =\cf5 8\cf4 )\cb1 \
\cb3     test_dataset = Dataset(\cf9 folder_path\cf4 =\cf10 ''\cf4 )\cb1 \
\cb3     test_train_data_loader = DataLoader(test_dataset\cf2 , \cf9 batch_size \cf4 = batch_size\cf2 , \cf9 shuffle\cf4 = \cf2 True, \cf9 num_workers\cf4 =\cf5 8\cf4 )\cb1 \
\
\cb3     optimizer = torch.optim.Adam(model.parameters90\cf2 , \cf9 Ir \cf4 = learning_rate)\cb1 \
\
\cb3     \cf2 for \cf4 epoch \cf2 in \cf8 range\cf4 (num_epochs):\cb1 \
\cb3         \cf2 for \cf4 i\cf2 , \cf4 (images\cf2 , \cf4 labels) \cf2 in \cf8 enumerate\cf4 (train_data_loader):\cb1 \
\
\cb3             images  = Variable(images.view(-\cf5 1\cf2 , \cf5 28\cf4 *\cf5 28\cf4 ))\cb1 \
\cb3             labels = Variable(labels)\cb1 \
\
\cb3             optimizer.zero_grad()\cb1 \
\cb3             outputs = model(images)\cb1 \
\cb3             loss = loss_func(labels\cf2 , \cf4 outputs)\cb1 \
\cb3             loss.backward()\cb1 \
\cb3             optimizer.step()\cb1 \
\
\cb3             \cf2 if\cf4 (i + \cf5 1\cf4 ) % \cf5 100 \cf4 ==\cf5 0\cf4 :\cb1 \
\cb3                 \cf8 print\cf4 (\cf10 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\cb1 \
\cb3                       \cf4 % (epoch + \cf5 1\cf2 , \cf4 num_epochs\cf2 , \cf4 i + \cf5 1\cf2 , \cf8 len\cf4 (train_dataset)// batch_size\cf2 , \cf4 loss.data[\cf5 0\cf4 ]))\cb1 \
\
\cb3                 correct = \cf5 0\cb1 \
\cb3                 \cf4 total = \cf5 0\cb1 \
\
\cb3                 \cf2 for \cf4 i\cf2 , \cf4 (images\cf2 , \cf4 labels) \cf2 in \cf8 enumerate\cf4 (test_data_loader):\cb1 \
\cb3                     images = Variable(images.view(-\cf5 1\cf2 , \cf5 28 \cf4 * \cf5 28\cf4 ))\cb1 \
\cb3                     labels = Variable(labels)\cb1 \
\cb3                     labels_y = torch.max(labels.data\cf2 , \cf5 1\cf4 )\cb1 \
\cb3                     outputs = model(images)\cb1 \
\cb3                     _\cf2 , \cf4 predicted = torch.max(outputs.data\cf2 , \cf5 1\cf4 )\cb1 \
\cb3                     total += labels.size(\cf5 0\cf4 )\cb1 \
\cb3                     correct += (labels_y[\cf5 1\cf4 ] == predicted).sum()\cb1 \
\cb3                 \cf8 print\cf4 (\cf10 'Accuracy of the network on the 10k test images: %d %%' \cf4 % (\cf5 100 \cf4 * correct / total))\
\
\uc0\u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \
\
\cf2 import \cf4 torch\cb1 \
\cf2 \cb3 import \cf4 torch.nn \cf2 as \cf4 nn\cb1 \
\cf2 \cb3 import \cf4 os\cb1 \
\cf2 \cb3 import \cf4 numpy \cf2 as \cf4 np\cb1 \
\cf2 \cb3 from \cf4 torch.utils.data \cf2 import \cf4 DataLoader\cb1 \
\cf2 \cb3 import \cf4 torchvision.datasets \cf2 as \cf4 dsets\cb1 \
\cf2 \cb3 import \cf4 torchvision.transforms \cf2 as \cf4 transforms\cb1 \
\
\cf2 \cb3 from \cf4 torch.autograd \cf2 import \cf4 variable\cb1 \
\cf2 \cb3 import \cf4 cv2\cb1 \
\
\cb3 input_size =\cf5 784\cb1 \
\cf4 \cb3 hidden_size = \cf5 50\cb1 \
\cf4 \cb3 num_classes = \cf5 10\cb1 \
\cf4 \cb3 num_epochs = \cf5 1\cb1 \
\cf4 \cb3 batch_size = \cf5 1\cb1 \
\cf4 \cb3 learning_rate = \cf5 0.001\cb1 \
\
\cf4 \cb3 model = MyNet(input_size\cf2 , \cf4 hidden-size\cf2 ,\cf4 num_classes)\cb1 \
\cb3 loss_func = MyLoss()\cb1 \
\cf2 \cb3 class \cf4 Dataset:\cb1 \
\cb3     \cf2 def \cf6 __init__\cf4 (\cf7 self\cf2 , \cf4 folder_path):\cb1 \
\cb3         \cf7 self\cf4 .n_classes = num_classes\cb1 \
\cb3         \cf7 self\cf4 .all_train_img_list = []\cb1 \
\cb3         \cf7 self\cf4 .all_train_label_list = []\cb1 \
\
\cb3         \cf2 for \cf4 i \cf2 in \cf8 range\cf4 (\cf7 self\cf4 .n_classes):\cb1 \
\cb3             \cf7 self\cf4 .train_list = os.listdir(\cf9 folder_path\cf4 =\cf8 str\cf4 (i))\cb1 \
\cb3             \cf7 self\cf4 .train_list = [folder_path+\cf8 str\cf4 (i)+\cf10 '/'\cf4 +file_name \cf2 for \cf4 file_name \cf2 in \cf7 self\cf4 .train_list]\cb1 \
\cb3             \cf7 self\cf4 .all_train_img_list = \cf7 self\cf4 .all_train_img_list+\cf7 self\cf4 .train_list\cb1 \
\cb3             \cf7 self\cf4 .all_train_img_list = \cf7 self\cf4 .all_train_label_list+[i]*\cf8 len\cf4 (\cf7 self\cf4 .train_list)\cb1 \
\
\cb3     \cf2 def \cf6 __getitem__\cf4 (\cf7 self\cf2 , \cf4 idx):\cb1 \
\cb3         img = cv2.inread(\cf7 self\cf4 .all_train_label_list[idx]\cf2 , \cf4 cv2.IMREAD_GRAYSCALE)\cb1 \
\cb3         img = np.expand_dims(img\cf2 , \cf5 0\cf4 )\cb1 \
\cb3         img = (img/\cf5 255.\cf4 ).astype(np.float32)\cb1 \
\cb3         label = \cf7 self\cf4 .all_train_label_list[idx]\cb1 \
\cb3         label = np.eye(\cf7 self\cf4 .n_classes)[label].astype(np.float32)\cb1 \
\cb3         \cf2 return \cf4 img\cf2 , \cf4 label\cb1 \
\
\cb3     \cf2 def \cf6 __len__\cf4 (\cf7 self\cf4 ):\cb1 \
\cb3         \cf2 return  \cf8 len\cf4 (\cf7 self\cf4 .all_train_img_list)\cb1 \
\
\cf2 \cb3 class \cf4 MyNet(torch.nn.Module):\cb1 \
\cb3     \cf2 def \cf6 __init__\cf4 (\cf7 self\cf2 ,\cf4 input_size\cf2 , \cf4 hidden_size\cf2 , \cf11 num_classes\cf4 ):\cb1 \
\cb3         \cf8 super\cf4 (MyNet\cf2 , \cf7 self\cf4 ).__intit__()\cb1 \
\cb3         \cf7 self\cf4 .fc1 = nn.Linear(input_size\cf2 , \cf4 hidden_size)\cb1 \
\cb3         \cf7 self\cf4 .relu = nn.ReLu()\cb1 \
\cb3         \cf7 self\cf4 .fc2 = nn.Linear(hidden_size\cf2 , \cf4 num-classes)\cb1 \
\
\cb3     \cf2 def \cf12 forward\cf4 (\cf7 self\cf2 , \cf4 x):\cb1 \
\cb3         out = \cf7 self\cf4 .fc1(x)\cb1 \
\cb3         out = \cf7 self\cf4 .relu(out)\cb1 \
\cb3         out = \cf7 self\cf4 .fc2(out)\cb1 \
\cb3         \cf2 return \cf4 out\cb1 \
\
\cf2 \cb3 class \cf4 MyLoss(torch.nn.Module):\cb1 \
\cb3     \cf2 def \cf6 __init__\cf4 (\cf7 self\cf4 ):\cb1 \
\cb3         \cf8 super\cf4 (MyLoss\cf2 , \cf7 self\cf4 ).\cf6 __init__\cf4 ()\cb1 \
\
\cb3     \cf2 def \cf12 forward\cf4 (\cf7 self\cf2 , \cf4 y\cf2 , \cf4 y_pred):\cb1 \
\cb3         \cf2 return \cf4 ((y-y_pred)**\cf5 2\cf4 ).mean()\cb1 \
\
\cf2 \cb3 if \cf4 __name__ = \cf10 '__main__'\cf4 :\cb1 \
\cb3     train_dataset = Dataset(\cf9 folder_path\cf4 =\cf10 ''\cf4 )\cb1 \
\cb3     train_data_loader = DataLoader(train_dataset\cf2 , \cf9 atch_size \cf4 = batch_size\cf2 , \cf9 shuffle \cf4 = \cf2 False, \cf9 num_workers\cf4 =\cf5 8\cf4 )\cb1 \
\cb3     test_dataset = Dataset(\cf9 folder_path\cf4 =\cf10 ''\cf4 )\cb1 \
\cb3     test_train_data_loader = DataLoader(test_dataset\cf2 , \cf9 batch_size \cf4 = batch_size\cf2 , \cf9 shuffle\cf4 = \cf2 True, \cf9 num_workers\cf4 =\cf5 8\cf4 )\cb1 \
\
\cb3     optimizer = torch.optim.Adam(model.parameters90\cf2 , \cf9 Ir \cf4 = learning_rate)\cb1 \
\
\
\
\
\
\
\cb3     \cf2 for \cf4 epoch \cf2 in \cf8 range\cf4 (num_epochs):\cb1 \
\cb3         \cf2 for \cf4 i\cf2 , \cf4 (images\cf2 , \cf4 labels) \cf2 in \cf8 enumerate\cf4 (train_data_loader):\cb1 \
\
\cb3             images  = Variable(images.view(-\cf5 1\cf2 , \cf5 28\cf4 *\cf5 28\cf4 ))\cb1 \
\cb3             labels = Variable(labels)\cb1 \
\
\cb3             optimizer.zero_grad()\cb1 \
\cb3             outputs = model(images)\cb1 \
\cb3             loss = loss_func(labels\cf2 , \cf4 outputs)\cb1 \
\cb3             loss.backward()\cb1 \
\cb3             optimizer.step()\cb1 \
\
\cb3             \cf2 if\cf4 (i + \cf5 1\cf4 ) % \cf5 100 \cf4 ==\cf5 0\cf4 :\cb1 \
\cb3                 \cf8 print\cf4 (\cf10 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\cb1 \
\cb3                       \cf4 % (epoch + \cf5 1\cf2 , \cf4 num_epochs\cf2 , \cf4 i + \cf5 1\cf2 , \cf8 len\cf4 (train_dataset)// batch_size\cf2 , \cf4 loss.data[\cf5 0\cf4 ]))\cb1 \
\
\
\cb3 correct = \cf5 0\cb1 \
\cf4 \cb3 total = \cf5 0\cb1 \
\
\cf2 \cb3 for \cf4 i\cf2 , \cf4 (images\cf2 , \cf4 labels) \cf2 in \cf8 enumerate\cf4 (test_data_loader):\cb1 \
\cb3     images = Variable(images.view(-\cf5 1\cf2 , \cf5 28 \cf4 * \cf5 28\cf4 ))\cb1 \
\cb3     labels = Variable(labels)\cb1 \
\cb3     labels_y = torch.max(labels.data\cf2 , \cf5 1\cf4 )\cb1 \
\cb3     outputs = model(images)\cb1 \
\cb3     _\cf2 , \cf4 predicted = torch.max(outputs.data\cf2 , \cf5 1\cf4 )\cb1 \
\cb3     total += labels.size(\cf5 0\cf4 )\cb1 \
\cb3     correct += (labels_y[\cf5 1\cf4 ] == predicted).sum()\cb1 \
\cb3     \cf8 print\cf4 (\cf10 'Accuracy of the network on the 10k test images: %d %%' \cf4 % (\cf5 100 \cf4 * correct / total))\
\
\
\
\
\uc0\u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \
\cf2 import \cf4 torch\cb1 \
\cf2 \cb3 from \cf4 torch.autograd \cf2 import \cf4 Variable\cb1 \
\cf2 \cb3 import \cf4 torch.nn.functional \cf2 as \cf4 F\cb1 \
\cf2 \cb3 import \cf4 torch.nn \cf2 as \cf4 nn\cb1 \
\cf2 \cb3 import \cf4 cv2\cb1 \
\cf2 \cb3 import \cf4 os\cb1 \
\cf2 \cb3 import \cf4 numpy \cf2 as \cf4 np\cb1 \
\cf2 \cb3 from \cf4 torch.utils.data \cf2 import \cf4 DataLoader\cb1 \
\
\cf2 \cb3 class \cf4 MyNet(torch.nn.Module):\cb1 \
\cb3     \cf2 def \cf6 __init__\cf4 (\cf7 self\cf4 ):\cb1 \
\cb3         \cf8 super\cf4 (MyNet\cf2 , \cf7 self\cf4 ).\cf6 __init__\cf4 ()\cb1 \
\cb3         \cf7 self\cf4 .conv1 = nn.Conv2d(\cf5 1\cf2 , \cf5 6\cf2 , \cf9 kernel_size\cf4 =\cf5 3\cf4 )\cb1 \
\cb3         \cf7 self\cf4 .conv2 = nn.Conv2d(\cf5 6\cf2 , \cf5 16\cf2 , \cf9 kernel_size\cf4 =\cf5 3\cf4 )\cb1 \
\cb3         \cf7 self\cf4 .fc1 = nn.Linear(\cf5 16\cf4 *\cf5 5\cf4 *\cf5 5\cf2 ,\cf5 120\cf4 )\cb1 \
\cb3         \cf7 self\cf4 .fc2 = nn.Linear(\cf5 120\cf2 ,\cf5 84\cf4 )\cb1 \
\cb3         \cf7 self\cf4 .fc3 = nn.Linear(\cf5 84\cf2 , \cf5 10\cf4 )\cb1 \
\
\cb3     \cf2 def \cf12 forward\cf4 (\cf7 self\cf2 , \cf4 x):\cb1 \
\cb3         x = F.relu(F.max_pool2d(\cf7 self\cf4 .conv1(x)\cf2 , \cf5 2\cf4 ))\cb1 \
\cb3         \cf11 #print(x.shape)\cb1 \
\cb3         \cf4 x = F.relu(F.max_pool2d(\cf7 self\cf4 .conv2(x)\cf2 ,\cf5 2\cf4 ))\cb1 \
\cb3         \cf11 #print(x.shape)\cb1 \
\cb3         \cf4 x = x.view(-\cf5 1\cf2 ,\cf5 16\cf4 *\cf5 5\cf4 *\cf5 5\cf4 )\cb1 \
\cb3         \cf11 #print(x.shape)\cb1 \
\cb3         \cf4 x = \cf7 self\cf4 .fc1(x)\cb1 \
\cb3         \cf11 #print(x.shape)\cb1 \
\cb3         \cf4 x = \cf7 self\cf4 .fc2(x)\cb1 \
\cb3         \cf11 #print(x.shape)\cb1 \
\cb3         \cf4 x = \cf7 self\cf4 .fc3(x)\cb1 \
\cb3         \cf11 #print(x.shape)\cb1 \
\cb3         \cf2 return \cf4 F.softmax(x\cf2 , \cf4 -\cf5 1\cf4 )\cb1 \
\
\cf2 \cb3 class \cf4 MyLoss(torch.nn.Module):\cb1 \
\cb3     \cf2 def \cf6 __init__\cf4 (\cf7 self\cf4 ):\cb1 \
\cb3         \cf8 super\cf4 (MyLoss\cf2 , \cf7 self\cf4 ).\cf6 __init__\cf4 ()\cb1 \
\cb3     \cf2 def \cf12 forward\cf4 (\cf7 self\cf2 , \cf4 y_pred\cf2 , \cf4 y):\cb1 \
\cb3         \cf2 return \cf4 ((y - y_pred)**\cf5 2\cf4 ).mean()\cb1 \
\
\cf2 \cb3 class \cf4 Dataset:\cb1 \
\cb3     \cf2 def \cf6 __init__\cf4 (\cf7 self\cf2 , \cf4 folder_path):\cb1 \
\cb3         \cf7 self\cf4 .n_classes = \cf5 10\cb1 \
\cb3         \cf7 self\cf4 .all_train_img_list = []\cb1 \
\cb3         \cf7 self\cf4 .all_train_label_list = []\cb1 \
\
\cb3         \cf2 for \cf4 i \cf2 in \cf8 range\cf4 (\cf7 self\cf4 .n_classes):\cb1 \
\cb3             train_list = os.listdir(folder_path + \cf8 str\cf4 (i))\cb1 \
\cb3             train_list = [folder_path + \cf8 str\cf4 (i) + \cf10 '/' \cf4 + filename \cf2 for \cf4 filename \cf2 in \cf4 train_list]\cb1 \
\cb3             \cf7 self\cf4 .all_train_img_list = \cf7 self\cf4 .all_train_img_list + train_list\cb1 \
\cb3             \cf7 self\cf4 .all_train_label_list = \cf7 self\cf4 .all_train_label_list + [i] * \cf8 len\cf4 (train_list)\cb1 \
\
\cb3     \cf2 def \cf6 __getitem__\cf4 (\cf7 self\cf2 , \cf4 idx):\cb1 \
\cb3         img = cv2.imread(\cf7 self\cf4 .all_train_img_list[idx]\cf2 , \cf4 cv2.IMREAD_GRAYSCALE)\cb1 \
\cb3         img = np.expand_dims(img\cf2 , \cf5 0\cf4 )\cb1 \
\cb3         img = (img/\cf5 255.\cf4 ).astype(np.float32)\cb1 \
\cb3         label = \cf7 self\cf4 .all_train_label_list[idx]\cb1 \
\cb3         label = np.eye(\cf7 self\cf4 .n_classes)[label].astype(np.float32)\cb1 \
\cb3         \cf2 return \cf4 img\cf2 , \cf4 label\cb1 \
\
\cb3     \cf2 def \cf6 __len__\cf4 (\cf7 self\cf4 ):\cb1 \
\cb3         \cf2 return \cf8 len\cf4 (\cf7 self\cf4 .all_train_img_list)\cb1 \
\
\
\
\cb3 num_epoch = \cf5 30\cb1 \
\cf4 \cb3 batch_size = \cf5 64\cb1 \
\cf4 \cb3 learning_rate = \cf5 1e-1\cb1 \
\
\
\cf2 \cb3 def \cf12 run\cf4 ():\cb1 \
\cb3     model = MyNet()\cb1 \
\cb3     loss_func = MyLoss()\cb1 \
\cb3     \cf11 accuracy\cf4 =[]\cb1 \
\cb3     \cf11 folder_path\cf4 =\cf10 'C:/Users/418-11/Desktop/mnist/mnist/train/'\cb1 \
\cb3     \cf4 train_dataset = Dataset(\cf9 folder_path\cf4 =\cf10 'C:/Users/418-11/Desktop/mnist/mnist/train/'\cf4 )\cb1 \
\cb3     train_data_loader = DataLoader(train_dataset\cf2 , \cf9 batch_size\cf4 =batch_size\cf2 , \cf9 shuffle\cf4 =\cf2 True, \cf9 num_workers\cf4 =\cf5 4\cf4 )\cb1 \
\
\cb3     val_dataset = Dataset(\cf9 folder_path\cf4 =\cf10 'C:/Users/418-11/Desktop/mnist/mnist/test/'\cf4 )\cb1 \
\cb3     val_data_loader = DataLoader(val_dataset\cf2 , \cf9 batch_size\cf4 =batch_size\cf2 , \cf9 shuffle\cf4 =\cf2 True, \cf9 num_workers\cf4 =\cf5 4\cf4 )\cb1 \
\
\
\cb3     \cf2 for \cf4 epoch \cf2 in \cf8 range\cf4 (num_epoch):\cb1 \
\cb3         epoch_loss = []\cb1 \
\cb3         \cf2 for \cf4 it\cf2 , \cf4 data \cf2 in \cf8 enumerate\cf4 (train_data_loader):\cb1 \
\cb3             x = data[\cf5 0\cf4 ]\cb1 \
\cb3             y = data[\cf5 1\cf4 ]\cb1 \
\
\cb3             y_pred = model(x)\cb1 \
\cb3             loss = loss_func(y_pred\cf2 , \cf4 y)\cb1 \
\
\cb3             \cf2 if \cf4 (it + \cf5 1\cf4 ) % \cf5 300 \cf4 == \cf5 0\cf4 :\cb1 \
\cb3                 \cf8 print\cf4 (\cf10 'Epoch: [%d/%d], Step: [%d/%d], Loss: %.4f' \cf4 % (epoch + \cf5 1\cf2 , \cf4 num_epoch\cf2 , \cf4 it + \cf5 1\cf2 , \cf5 600\cf2 , \cf4 np.array(epoch_loss).mean()))\cb1 \
\cb3             \cf2 for \cf4 param \cf2 in \cf4 model.parameters():\cb1 \
\cb3                 \cf2 if \cf4 param.grad \cf2 is not None\cf4 :\cb1 \
\cb3                     param.grad.data.zero_()\cb1 \
\cb3             loss.backward()\cb1 \
\
\cb3             \cf2 for \cf4 param \cf2 in \cf4 model.parameters():\cb1 \
\cb3                 param.data -= learning_rate * param.grad.data\cb1 \
\cb3             epoch_loss.append(loss.item())\cb1 \
\cb3         val_epoch_loss = []\cb1 \
\
\cb3         correct = \cf5 0\cb1 \
\cb3         \cf4 total = \cf5 0\cb1 \
\
\cb3         \cf2 for \cf4 data \cf2 in \cf4 val_data_loader:\cb1 \
\cb3             x = data[\cf5 0\cf4 ]\cb1 \
\cb3             y = data[\cf5 1\cf4 ]\cb1 \
\cb3             y_pred = model(x)\cb1 \
\
\cb3             _\cf2 , \cf4 label_pred = torch.max(y_pred\cf2 , \cf5 1\cf4 )\cb1 \
\cb3             _\cf2 , \cf4 label = torch.max(y\cf2 , \cf5 1\cf4 )\cb1 \
\
\cb3             total += label.size(\cf5 0\cf4 )\cb1 \
\cb3             correct += (label == label_pred).sum()\cb1 \
\
\cb3             loss = loss_func(y_pred\cf2 , \cf4 y)\cb1 \
\cb3             val_epoch_loss.append(loss.item())\cb1 \
\cb3     \cf8 print\cf4 (\cf10 'validation loss : '\cf2 , \cf4 np.array(val_epoch_loss).mean())\cb1 \
\cb3     \cf8 print\cf4 (\cf10 'epoch : [%d/%d] Accuracy: %d%%' \cf4 % (epoch + \cf5 1\cf2 , \cf4 num_epoch\cf2 , \cf5 100 \cf4 * correct / total))\cb1 \
\
\cf2 \cb3 if \cf4 __name__ == \cf10 '__main__'\cf4 :\cb1 \
\cb3     run()\
\
\
\
\uc0\u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \u8212 \
\
\
\
\cf2 import \cf4 torch\cb1 \
\cf2 \cb3 from \cf4 torch.autograd \cf2 import \cf4 Variable\cb1 \
\cf2 \cb3 import \cf4 torch.nn.functional \cf2 as \cf4 F\cb1 \
\cf2 \cb3 import \cf4 torch.nn \cf2 as \cf4 nn\cb1 \
\cf2 \cb3 import \cf4 cv2\cb1 \
\cf2 \cb3 import \cf4 os\cb1 \
\cf2 \cb3 import \cf4 numpy \cf2 as \cf4 np\cb1 \
\cf2 \cb3 from \cf4 torch.utils.data \cf2 import \cf4 DataLoader\cb1 \
\cf2 \cb3 from \cf4 torch.optim \cf2 import \cf4 SGD\cb1 \
\
\cf2 \cb3 class \cf4 MyNet(torch.nn.Module):\cb1 \
\cb3     \cf2 def \cf6 __init__\cf4 (\cf7 self\cf4 ):\cb1 \
\cb3         \cf8 super\cf4 (MyNet\cf2 , \cf7 self\cf4 ).\cf6 __init__\cf4 ()\cb1 \
\cb3         \cf7 self\cf4 .conv1 = nn.Conv2d(\cf5 3\cf2 , \cf5 6\cf2 , \cf9 kernel_size\cf4 =\cf5 5\cf4 )\cb1 \
\cb3         \cf7 self\cf4 .conv2 = nn.Conv2d(\cf5 6\cf2 , \cf5 16\cf2 , \cf9 kernel_size\cf4 =\cf5 5\cf4 )\cb1 \
\cb3         \cf7 self\cf4 .fc1 = nn.Linear(\cf5 16\cf4 *\cf5 5\cf4 *\cf5 5\cf2 ,\cf5 120\cf4 )\cb1 \
\cb3         \cf7 self\cf4 .fc2 = nn.Linear(\cf5 120\cf2 ,\cf5 84\cf4 )\cb1 \
\cb3         \cf7 self\cf4 .fc3 = nn.Linear(\cf5 84\cf2 , \cf5 10\cf4 )\cb1 \
\
\cb3     \cf2 def \cf12 forward\cf4 (\cf7 self\cf2 , \cf4 x):\cb1 \
\cb3         x = F.relu(F.max_pool2d(\cf7 self\cf4 .conv1(x)\cf2 , \cf5 2\cf4 ))\cb1 \
\cb3         \cf11 #print(x.shape)\cb1 \
\cb3         \cf4 x = F.relu(F.max_pool2d(\cf7 self\cf4 .conv2(x)\cf2 ,\cf5 2\cf4 ))\cb1 \
\cb3         \cf11 #print(x.shape)\cb1 \
\cb3         \cf4 x = x.view(-\cf5 1\cf2 ,\cf5 16\cf4 *\cf5 5\cf4 *\cf5 5\cf4 )\cb1 \
\cb3         \cf11 #print(x.shape)\cb1 \
\cb3         \cf4 x = \cf7 self\cf4 .fc1(x)\cb1 \
\cb3         \cf11 #print(x.shape)\cb1 \
\cb3         \cf4 x = \cf7 self\cf4 .fc2(x)\cb1 \
\cb3         \cf11 #print(x.shape)\cb1 \
\cb3         \cf4 x = \cf7 self\cf4 .fc3(x)\cb1 \
\cb3         \cf11 #print(x.shape)\cb1 \
\cb3         \cf2 return \cf4 F.softmax(x\cf2 , \cf4 -\cf5 1\cf4 )\cb1 \
\
\cf2 \cb3 class \cf4 MyNet1(torch.nn.Module):\cb1 \
\cb3     \cf2 def \cf6 __init__\cf4 (\cf7 self\cf4 ):\cb1 \
\cb3         \cf8 super\cf4 (MyNet\cf2 , \cf7 self\cf4 ).\cf6 __init__\cf4 ()\cb1 \
\cb3         \cf11 ##\'bf\'a9\'b1\'e2\'bf\'a1 \'b3\'d7\'c6\'ae\'bf\'f6\'c5\'a9 \'bc\'b3\'b0\'e8##\cb1 \
\cb3         \cf7 self\cf4 .conv1 = nn.Conv2d(\cf5 3\cf2 , \cf5 4\cf2 , \cf9 kernel_size\cf4 =\cf5 3\cf2 , \cf9 padding\cf4 =\cf5 1\cf4 )\cb1 \
\cb3         \cf7 self\cf4 .conv2 = nn.Conv2d(\cf5 4\cf2 , \cf5 4\cf2 , \cf9 kernel_size\cf4 =\cf5 3\cf2 , \cf9 padding\cf4 =\cf5 1\cf4 )\cb1 \
\
\cb3     \cf2 def \cf12 forward\cf4 (\cf7 self\cf2 , \cf4 x):\cb1 \
\cb3         x = F.relu(F.max_pool2d(\cf7 self\cf4 .conv1(x)\cf2 , \cf5 2\cf4 ))\cb1 \
\cb3         x = F.relu(F.max_pool2d(\cf7 self\cf4 .conv2(x)\cf2 , \cf5 2\cf4 ))\cb1 \
\
\cb3         \cf2 return \cf4 F.softmax(x\cf2 , \cf4 -\cf5 1\cf4 )\cb1 \
\
\cf2 \cb3 class \cf4 MyLoss(torch.nn.Module):\cb1 \
\cb3     \cf2 def \cf6 __init__\cf4 (\cf7 self\cf4 ):\cb1 \
\cb3         \cf8 super\cf4 (MyLoss\cf2 , \cf7 self\cf4 ).\cf6 __init__\cf4 ()\cb1 \
\cb3     \cf2 def \cf12 forward\cf4 (\cf7 self\cf2 , \cf4 y_pred\cf2 , \cf4 y):\cb1 \
\cb3         \cf2 return \cf4 ((y - y_pred)**\cf5 2\cf4 ).mean()\cb1 \
\
\
\cf2 \cb3 class \cf4 Dataset:\cb1 \
\cb3     \cf2 def \cf6 __init__\cf4 (\cf7 self\cf2 , \cf4 folder_path):\cb1 \
\cb3         \cf7 self\cf4 .all_train_img_list = []\cb1 \
\cb3         train_list = os.listdir(folder_path)\cb1 \
\cb3         train_list = [folder_path + filename \cf2 for \cf4 filename \cf2 in \cf4 train_list]\cb1 \
\cb3         \cf7 self\cf4 .all_train_img_list = \cf7 self\cf4 .all_train_img_list + train_list\cb1 \
\
\cb3     \cf2 def \cf6 __getitem__\cf4 (\cf7 self\cf2 , \cf4 idx):\cb1 \
\cb3         img = cv2.imread(\cf7 self\cf4 .all_train_img_list[idx]\cf2 , \cf4 cv2.IMREAD_COLOR)\cb1 \
\cb3         img = cv2.resize(img\cf2 , \cf4 (\cf5 224\cf2 ,\cf5 224\cf4 ))\cb1 \
\cb3         img = np.transpose(img\cf2 , \cf4 (\cf5 2\cf2 , \cf5 0\cf2 , \cf5 1\cf4 ))\cb1 \
\cb3         img = (img/\cf5 255.\cf4 ).astype(np.float32)\cb1 \
\cb3         img = torch.from_numpy(img)\cb1 \
\cb3         label_list = [\cf10 'cat'\cf2 , \cf10 'dog'\cf4 ]\cb1 \
\cb3         label = \cf7 self\cf4 .all_train_img_list[idx].split(\cf10 '/'\cf4 )[-\cf5 1\cf4 ][:\cf5 3\cf4 ]\cb1 \
\cb3         label = np.eye(\cf8 len\cf4 (label_list))[label_list.index(label)].astype(np.float32)\cb1 \
\cb3         label = torch.from_numpy(label)\cb1 \
\cb3         \cf2 return \cf4 img\cf2 , \cf4 label\cb1 \
\
\cb3     \cf2 def \cf6 __len__\cf4 (\cf7 self\cf4 ):\cb1 \
\cb3         \cf2 return \cf8 len\cf4 (\cf7 self\cf4 .all_train_img_list)\cb1 \
\
\
\cb3 num_epoch = \cf5 50\cb1 \
\cf4 \cb3 batch_size = \cf5 64\cb1 \
\cf4 \cb3 learning_rate = \cf5 1e-1\cb1 \
\
\
\cf2 \cb3 def \cf12 run\cf4 ():\cb1 \
\cb3     model = MyNet()\cb1 \
\cb3     loss_func = MyLoss()\cb1 \
\cb3     \cf11 accuracy \cf4 = []\cb1 \
\cb3     train_dataset = Dataset(\cf9 folder_path\cf4 =\cf10 'C:/Users/418-11/Downloads/DogAndCat/train/'\cf4 )\cb1 \
\cb3     train_data_loader = DataLoader(train_dataset\cf2 , \cf9 batch_size\cf4 =batch_size\cf2 , \cf9 shuffle\cf4 =\cf2 True, \cf9 num_workers\cf4 =\cf5 4\cf4 )\cb1 \
\
\cb3     val_dataset = Dataset(\cf9 folder_path\cf4 =\cf10 'C:/Users/418-11/Downloads\\DogAndCat/test/'\cf4 )\cb1 \
\cb3     val_data_loader = DataLoader(val_dataset\cf2 , \cf9 batch_size\cf4 =batch_size\cf2 , \cf9 shuffle\cf4 =\cf2 True, \cf9 num_workers\cf4 =\cf5 4\cf4 )\cb1 \
\cb3     optimizer = SGD(model.parameters()\cf2 , \cf9 lr\cf4 =\cf5 1e-3\cf2 , \cf9 momentum\cf4 =\cf5 0.9\cf4 )\cb1 \
\
\
\cb3     \cf2 for \cf4 epoch \cf2 in \cf8 range\cf4 (num_epoch):\cb1 \
\cb3             epoch_loss = []\cb1 \
\cb3             \cf2 for \cf4 it\cf2 , \cf4 data \cf2 in \cf8 enumerate\cf4 (train_data_loader):\cb1 \
\cb3                 x = data[\cf5 0\cf4 ]\cb1 \
\cb3                 y = data[\cf5 1\cf4 ]\cb1 \
\cb3                 y_pred = model(x)\cb1 \
\cb3                 loss = loss_func(y_pred\cf2 , \cf4 y)\cb1 \
\cb3                 optimizer.zero_grad()\cb1 \
\cb3                 \cf2 if \cf4 (it+\cf5 1\cf4 )  % \cf5 100 \cf4 == \cf5 0\cf4 :\cb1 \
\cb3                     \cf8 print\cf4 (\cf10 'Epoch: [%d/%d], Step: [%d/%d], Loss: %.4f' \cf4 %(epoch+\cf5 1\cf2 ,\cf4 num_epoch\cf2 , \cf4 it+\cf5 1\cf2 , \cf8 len\cf4 (train_data_loader)\cf2 ,  \cf4 loss ))\cb1 \
\cb3                 \cf2 for \cf4 param \cf2 in \cf4 model.parameters():\cb1 \
\cb3                     \cf2 if \cf4 param.grad \cf2 is not None\cf4 :\cb1 \
\cb3                         param.grad.data.zero_()\cb1 \
\cb3                 loss.backward()\cb1 \
\cb3                 optimizer.step()\cb1 \
\cb3                 \cf2 for \cf4 param \cf2 in \cf4 model.parameters():\cb1 \
\cb3                     param.data -= learning_rate * param.grad.data\cb1 \
\cb3                 epoch_loss.append(loss.item())\cb1 \
\cb3             val_epoch_loss = []\cb1 \
\
\cb3             correct = \cf5 0\cb1 \
\cb3             \cf4 total = \cf5 0\cb1 \
\cb3             \cf2 for \cf4 data \cf2 in \cf4 val_data_loader:\cb1 \
\cb3                 x = data[\cf5 0\cf4 ]\cb1 \
\cb3                 y = data[\cf5 1\cf4 ]\cb1 \
\cb3                 y_pred = model(x)\cb1 \
\
\
\cb3                 _\cf2 , \cf4 label_pred = torch.max(y_pred\cf2 , \cf5 1\cf4 )\cb1 \
\cb3                 _\cf2 , \cf4 label = torch.max(y\cf2 , \cf5 1\cf4 )\cb1 \
\
\cb3                 total += label.size(\cf5 0\cf4 )\cb1 \
\cb3                 correct += (label == label_pred).sum()\cb1 \
\
\cb3                 loss = loss_func(y_pred\cf2 , \cf4 y)\cb1 \
\cb3                 val_epoch_loss.append(loss.item())\cb1 \
\cb3             \cf8 print\cf4 (\cf10 'validation loss : '\cf2 , \cf4 np.array(val_epoch_loss).mean())\cb1 \
\cb3             \cf8 print\cf4 (\cf10 'epoch : [%d/%d] Accuracy: %d%%'  \cf4 % (epoch+\cf5 1\cf2 , \cf4 num_epoch\cf2 , \cf5 100 \cf4 * correct / total))\cb1 \
\
\
\cf2 \cb3 if \cf4 __name__ == \cf10 "__main__"\cf4 :\cb1 \
\cb3     run()}